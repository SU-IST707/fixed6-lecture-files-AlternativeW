{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7058fd1f",
   "metadata": {},
   "source": [
    "# Exercise 1: Parameter-Driven Regularization\n",
    "\n",
    "In this exercise, you'll create three models with different regularization strategies and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b5939",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# Create a validation set\n",
    "X_train = X_train_full[:-5000] / 255.0\n",
    "X_valid = X_train_full[-5000:] / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = y_train_full[:-5000]\n",
    "y_valid = y_train_full[-5000:]\n",
    "\n",
    "# Exercise 1: Impact of L1 vs L2 Regularization\n",
    "# -------------------------------------------\n",
    "\n",
    "\n",
    "def create_model(reg_type=None, reg_rate=0.001):  # Note the smaller default reg_rate\n",
    "    \"\"\"\n",
    "    Create a model with specified regularization.\n",
    "    \n",
    "    Parameters:\n",
    "    reg_type: str, one of ['l1', 'l2', 'l1_l2', None]\n",
    "    reg_rate: float, regularization rate\n",
    "    \n",
    "    Returns:\n",
    "    Compiled Keras model\n",
    "    \"\"\"\n",
    "    # TODO: Complete the regularizer selection based on reg_type\n",
    "    if reg_type == 'l1':\n",
    "        regularizer = # Your code here\n",
    "    elif reg_type == 'l2':\n",
    "        regularizer = # Your code here\n",
    "    elif reg_type == 'l1_l2':\n",
    "        regularizer = # Your code here\n",
    "    else:\n",
    "        regularizer = None\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                            kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\", \n",
    "                            kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    # TODO: Complete model compilation with appropriate optimizer and learning rate\n",
    "    optimizer = # Your code here: Create an SGD optimizer with learning_rate=0.01\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "def train_and_compare_models():\n",
    "    \"\"\"Train models with different regularization and plot results.\"\"\"\n",
    "    \n",
    "    # TODO: Create three models with different regularization\n",
    "    model_no_reg = # Your code here: Create model with no regularization\n",
    "    model_l1 = # Your code here: Create model with L1 regularization (rate=0.0001)\n",
    "    model_l2 = # Your code here: Create model with L2 regularization (rate=0.001)\n",
    "    \n",
    "    # Train models\n",
    "    history_no_reg = model_no_reg.fit(X_train, y_train, epochs=10, \n",
    "                                     validation_data=(X_valid, y_valid),\n",
    "                                     verbose=1)\n",
    "    history_l1 = model_l1.fit(X_train, y_train, epochs=10,\n",
    "                             validation_data=(X_valid, y_valid),\n",
    "                             verbose=1)\n",
    "    history_l2 = model_l2.fit(X_train, y_train, epochs=10,\n",
    "                             validation_data=(X_valid, y_valid),\n",
    "                             verbose=1)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_no_reg.history['loss'], label='No regularization')\n",
    "    plt.plot(history_l1.history['loss'], label='L1')\n",
    "    plt.plot(history_l2.history['loss'], label='L2')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss')\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_no_reg.history['val_accuracy'], label='No regularization')\n",
    "    plt.plot(history_l1.history['val_accuracy'], label='L1')\n",
    "    plt.plot(history_l2.history['val_accuracy'], label='L2')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return model_no_reg, model_l1, model_l2\n",
    "\n",
    "models = train_and_compare_models()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390432b3",
   "metadata": {},
   "source": [
    "# Exercise 2: Dropout Regularization\n",
    "\n",
    "In this exercise, you'll explore how dropout affects model training and inference in neural networks. You'll implement different dropout strategies and visualize their effects on model performance.\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n",
    "First, let's load and prepare our Fashion MNIST data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3fbc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# Create a validation set\n",
    "X_train = X_train_full[:-5000] / 255.0\n",
    "X_valid = X_train_full[-5000:] / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = y_train_full[:-5000]\n",
    "y_valid = y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137b5c5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 2: Building Models with Different Dropout Configurations\n",
    "\n",
    "We'll create a function that builds models with different dropout patterns. Fill in the missing pieces:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d165b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout_pattern):\n",
    "    \"\"\"\n",
    "    Create a model with specified dropout pattern.\n",
    "    \n",
    "    Parameters:\n",
    "    dropout_pattern: list of float, dropout rates for each layer (use None for no dropout)\n",
    "    \n",
    "    Returns:\n",
    "    Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    \n",
    "    # TODO: Add three Dense layers (100 neurons each) with ReLU activation\n",
    "    # Add dropout after each Dense layer according to dropout_pattern\n",
    "    # Your code here:\n",
    "    for rate in dropout_pattern:\n",
    "        model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "        if rate is not None:\n",
    "            # Add dropout layer with specified rate\n",
    "            pass\n",
    "    \n",
    "    # Add output layer\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    # TODO: Compile the model with appropriate optimizer and metrics\n",
    "    # Your code here:\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138de74",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 3: Training and Evaluation\n",
    "\n",
    "Let's create a function to train and compare different dropout configurations:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f5401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dropout_patterns():\n",
    "    \"\"\"Train and compare models with different dropout patterns.\"\"\"\n",
    "    \n",
    "    # Define different dropout patterns to test\n",
    "    patterns = {\n",
    "        'No Dropout': [None, None, None],\n",
    "        'Uniform Dropout': [0.2, 0.2, 0.2],\n",
    "        'Increasing Dropout': [0.1, 0.2, 0.3]\n",
    "    }\n",
    "    \n",
    "    histories = {}\n",
    "    \n",
    "    # TODO: Train a model for each dropout pattern\n",
    "    # Your code here:\n",
    "    for name, pattern in patterns.items():\n",
    "        model = # Create model with pattern\n",
    "        history = # Train model for 10 epochs with validation data\n",
    "        histories[name] = history\n",
    "    \n",
    "    return histories\n",
    "\n",
    "def plot_training_curves(histories):\n",
    "    \"\"\"Plot training and validation metrics for different models.\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for name, history in histories.items():\n",
    "        # TODO: Plot training loss for each model\n",
    "        # Your code here:\n",
    "        pass\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss')\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for name, history in histories.items():\n",
    "        # TODO: Plot validation accuracy for each model\n",
    "        # Your code here:\n",
    "        pass\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "histories = compare_dropout_patterns()\n",
    "plot_training_curves(histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b945c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Questions to Consider:\n",
    "\n",
    "1. How does the validation accuracy compare between different dropout patterns?\n",
    "2. What effect does dropout have on training time?\n",
    "3. How does Monte Carlo Dropout affect the model's predictions compared to standard inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de45387e",
   "metadata": {},
   "source": [
    "# Exercise 3: Max-Norm Regularization\n",
    "\n",
    "In this exercise, you'll explore how max-norm regularization affects neural network training and compare it with other regularization techniques. You'll visualize the weight distributions and see how different max-norm constraints impact model performance.\n",
    "\n",
    "## Part 1: Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ee270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# Create a validation set\n",
    "X_train = X_train_full[:-5000] / 255.0\n",
    "X_valid = X_train_full[-5000:] / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = y_train_full[:-5000]\n",
    "y_valid = y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbfd0c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 2: Model Creation with Max-Norm Constraints\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_norm=None):\n",
    "    \"\"\"\n",
    "    Create a model with specified max-norm constraint.\n",
    "    \n",
    "    Parameters:\n",
    "    max_norm: float or None, maximum norm constraint for the weights\n",
    "    \n",
    "    Returns:\n",
    "    Compiled Keras model\n",
    "    \"\"\"\n",
    "    # TODO: Create kernel_constraint \n",
    "    constraint = # Your code here\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        # TODO: Add Dense layers with the max_norm constraint\n",
    "        # Your code here: Three Dense layers (100 neurons) with ReLU activation\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    # TODO: Compile model with SGD optimizer (lr=0.01) and appropriate metrics\n",
    "    # Your code here\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9054c7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 3: Training and Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_compare_norms():\n",
    "    \"\"\"Train models with different max-norm constraints and compare results.\"\"\"\n",
    "    \n",
    "    # Create models with different max-norm constraints\n",
    "    models = {\n",
    "        'No Constraint': create_model(max_norm=None),\n",
    "        'MaxNorm(1)': create_model(max_norm=1.0),\n",
    "        'MaxNorm(.5)': create_model(max_norm=.5)\n",
    "    }\n",
    "    \n",
    "    histories = {}\n",
    "    \n",
    "    # Train each model\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}\")\n",
    "        # TODO: Train model for 10 epochs and store history\n",
    "        # Your code here\n",
    "    \n",
    "    return models, histories\n",
    "\n",
    "def plot_weight_distributions(models, layer_index=1):\n",
    "    \"\"\"Plot weight distributions for a specific layer across models.\"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        # TODO: Extract weights from the specified layer\n",
    "        weights = # Your code here\n",
    "        \n",
    "        # Create subplot\n",
    "        plt.subplot(1, 3, idx + 1)\n",
    "        \n",
    "        # TODO: Plot histogram of weights\n",
    "        # Your code here: use plt.hist with appropriate bins and range\n",
    "        \n",
    "        plt.title(f'{name}\\nStd: {weights.std():.4f}')\n",
    "        plt.xlabel('Weight Value')\n",
    "        plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_training_curves(histories):\n",
    "    \"\"\"Plot training and validation metrics.\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for name, history in histories.items():\n",
    "        # TODO: Plot training loss for each model\n",
    "        # Your code here\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training Loss')\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for name, history in histories.items():\n",
    "        # TODO: Plot validation accuracy for each model\n",
    "        # Your code here\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f6944f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 4: Weight Norm Evolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6a04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightNormCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Callback to track weight norm evolution during training.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight_norms = []\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # TODO: Calculate and store the norm of weights from the first dense layer\n",
    "        # Your code here\n",
    "        pass\n",
    "\n",
    "def plot_norm_evolution(model, X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"Train a model and plot how its weight norms evolve.\"\"\"\n",
    "    \n",
    "    # Create callback\n",
    "    norm_callback = WeightNormCallback()\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[norm_callback],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Plot norm evolution\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(norm_callback.weight_norms)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Weight Norm')\n",
    "    plt.title('Evolution of Weight Norms During Training')\n",
    "    plt.show()\n",
    "\n",
    "# Run the experiments\n",
    "\n",
    "models, histories = train_and_compare_norms()\n",
    "plot_training_curves(histories)\n",
    "plot_weight_distributions(models)\n",
    "\n",
    "# Demonstrate norm evolution for a model with max_norm=1.0\n",
    "constrained_model = create_model(max_norm=1.0)\n",
    "plot_norm_evolution(constrained_model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a336ee",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Questions to Consider:\n",
    "\n",
    "1. How does the max-norm constraint affect the distribution of weights?\n",
    "2. What impact does the constraint value have on model performance?\n",
    "3. How does training stability compare between constrained and unconstrained models?\n",
    "4. In what scenarios might max-norm regularization be preferable to L1 or L2 regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9172c22f",
   "metadata": {},
   "source": [
    "# Exercise 4: Monte Carlo Dropout\n",
    "\n",
    "In this exercise, you'll explore how Monte Carlo Dropout can be used for uncertainty estimation in neural networks. You'll implement MC Dropout, visualize uncertainty estimates, and compare predictions with and without uncertainty estimation.\n",
    "\n",
    "## Part 1: Setup and Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f26716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# Create a validation set\n",
    "X_train = X_train_full[:-5000] / 255.0\n",
    "X_valid = X_train_full[-5000:] / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_train = y_train_full[:-5000]\n",
    "y_valid = y_train_full[-5000:]\n",
    "\n",
    "# Class names for Fashion MNIST\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f9ef36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 2: Creating an MC Dropout Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b28d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    \"\"\"Dropout layer that applies dropout at inference time.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        # TODO: Modify the call method to always apply dropout\n",
    "        # Hint: Use super().call() with training=True\n",
    "        pass\n",
    "\n",
    "def create_mc_model(dropout_rate=0.3):\n",
    "    \"\"\"Create a model with MC Dropout layers.\"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        # TODO: Add MCDropout layer with dropout_rate\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        # TODO: Add MCDropout layer with dropout_rate\n",
    "        tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "        # TODO: Add MCDropout layer with dropout_rate\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    # TODO: Compile the model\n",
    "    # Your code here\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a83018",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 3: Implementing Monte Carlo Predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_predict(model, X, num_samples=100):\n",
    "    \"\"\"\n",
    "    Make predictions with MC Dropout.\n",
    "    \n",
    "    Parameters:\n",
    "    model: keras model with MC Dropout layers\n",
    "    X: input data\n",
    "    num_samples: number of predictions to average\n",
    "    \n",
    "    Returns:\n",
    "    mean_pred: mean of predictions\n",
    "    std_pred: standard deviation of predictions\n",
    "    \"\"\"\n",
    "    # TODO: Generate multiple predictions and calculate statistics\n",
    "    # Your code here: Use model.predict() multiple times\n",
    "    # Calculate mean and standard deviation across predictions\n",
    "    \n",
    "    return mean_pred, std_pred\n",
    "\n",
    "def plot_uncertainty(model, X_samples, y_true, num_samples=100):\n",
    "    \"\"\"Plot predictions with uncertainty bars.\"\"\"\n",
    "    # Get predictions and uncertainty\n",
    "    mean_pred, std_pred = mc_predict(model, X_samples, num_samples)\n",
    "    \n",
    "    # Convert predictions to class labels and confidence\n",
    "    pred_labels = np.argmax(mean_pred, axis=1)\n",
    "    confidence = np.max(mean_pred, axis=1)\n",
    "    uncertainty = np.mean(std_pred, axis=1)\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot confidence vs uncertainty\n",
    "    scatter = axes[0].scatter(confidence, uncertainty, \n",
    "                            c=(pred_labels == y_true), cmap='RdYlGn')\n",
    "    axes[0].set_xlabel('Confidence (Max Probability)')\n",
    "    axes[0].set_ylabel('Uncertainty (Mean Std)')\n",
    "    axes[0].set_title('Confidence vs Uncertainty')\n",
    "    plt.colorbar(scatter, ax=axes[0], label='Correct Prediction')\n",
    "    \n",
    "    # Plot correct vs incorrect predictions\n",
    "    correct_conf = confidence[pred_labels == y_true]\n",
    "    correct_unc = uncertainty[pred_labels == y_true]\n",
    "    incorrect_conf = confidence[pred_labels != y_true]\n",
    "    incorrect_unc = uncertainty[pred_labels != y_true]\n",
    "    \n",
    "    axes[1].hist(uncertainty[pred_labels == y_true], \n",
    "                 alpha=0.5, label='Correct', bins=20)\n",
    "    axes[1].hist(uncertainty[pred_labels != y_true], \n",
    "                 alpha=0.5, label='Incorrect', bins=20)\n",
    "    axes[1].set_xlabel('Uncertainty')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title('Uncertainty Distribution')\n",
    "    axes[1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return mean_pred, std_pred\n",
    "\n",
    "def visualize_uncertain_predictions(model, X_samples, y_true, num_samples=100):\n",
    "    \"\"\"Visualize images with their predictions and uncertainty.\"\"\"\n",
    "    mean_pred, std_pred = mc_predict(model, X_samples, num_samples)\n",
    "    \n",
    "    # Select most uncertain predictions\n",
    "    uncertainty = np.mean(std_pred, axis=1)\n",
    "    most_uncertain = np.argsort(uncertainty)[-5:]  # Get 5 most uncertain\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, idx in enumerate(most_uncertain):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X_samples[idx].reshape(28, 28), cmap='binary')\n",
    "        pred_label = np.argmax(mean_pred[idx])\n",
    "        plt.title(f'Pred: {class_names[pred_label]}\\nTrue: {class_names[y_true[idx]]}\\nUnc: {uncertainty[idx]:.3f}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be48092",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 4: Training and Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5608224",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create and train model\n",
    "model = create_mc_model()\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Evaluate on test set\n",
    "test_samples = X_test[:1000]  # Using a subset for visualization\n",
    "test_labels = y_test[:1000]\n",
    "\n",
    "# Plot uncertainty analysis\n",
    "plot_uncertainty(model, test_samples, test_labels)\n",
    "\n",
    "# Visualize most uncertain predictions\n",
    "visualize_uncertain_predictions(model, test_samples, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4d36e9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Questions to Consider:\n",
    "\n",
    "1. How does the uncertainty (standard deviation) correlate with prediction accuracy?\n",
    "2. What types of images tend to have higher uncertainty in their predictions?\n",
    "3. How might you use uncertainty estimates in a real-world application?\n",
    "4. How does the number of MC samples affect the stability of uncertainty estimates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aed378",
   "metadata": {},
   "source": [
    "# Exercise 5: Hyperparameter Tuning\n",
    "\n",
    "In this exercise, you'll explore hyperparameter tuning using Keras Tuner. You'll implement different search strategies and visualize their results, while keeping the computational requirements reasonable.\n",
    "\n",
    "## Part 1: Setup and Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06175ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "# Load and preprocess Fashion MNIST data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "\n",
    "# Use a smaller subset for quicker training\n",
    "train_size = 5000\n",
    "test_size = 1000\n",
    "\n",
    "# Create validation set\n",
    "X_train = X_train_full[:train_size] / 255.0\n",
    "X_valid = X_train_full[train_size:train_size+1000] / 255.0\n",
    "X_test = X_test[:test_size] / 255.0\n",
    "\n",
    "y_train = y_train_full[:train_size]\n",
    "y_valid = y_train_full[train_size:train_size+1000]\n",
    "y_test = y_test[:test_size]\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_valid)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3327cdb5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 2: Define the Model Building Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1303e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Build model with hyperparameters to tune.\n",
    "    \n",
    "    Parameters:\n",
    "    hp: Keras Tuner hyperparameters object\n",
    "    \n",
    "    Returns:\n",
    "    Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=[28, 28]))\n",
    "    \n",
    "    # TODO: Add hp.Int for number of hidden layers (1-3)\n",
    "    n_hidden = # Your code here\n",
    "    \n",
    "    # TODO: Add hp.Int for number of neurons (32-128 in steps of 32)\n",
    "    n_neurons = # Your code here\n",
    "    \n",
    "    # TODO: Add hp.Choice for activation function ('relu', 'tanh')\n",
    "    activation = # Your code here\n",
    "    \n",
    "    # Build hidden layers\n",
    "    for _ in range(n_hidden):\n",
    "        # TODO: Add Dense layer with tunable neurons and activation\n",
    "        # Your code here\n",
    "        \n",
    "        # TODO: Add hp.Float for dropout rate (0-0.5)\n",
    "        dropout_rate = # Your code here\n",
    "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    # TODO: Add hp.Float for learning rate (log-scale between 0.0001 and 0.01)\n",
    "    learning_rate = # Your code here\n",
    "    \n",
    "    # TODO: Add hp.Choice for optimizer ('sgd', 'adam')\n",
    "    optimizer_choice = # Your code here\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate) if optimizer_choice == 'sgd' \\\n",
    "        else tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ad1c8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 3: Implement Different Search Strategies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuner(tuner_type='random', max_trials=10, overwrite=True):\n",
    "    \"\"\"\n",
    "    Run hyperparameter search with specified tuner.\n",
    "    \n",
    "    Parameters:\n",
    "    tuner_type: str, one of ['random', 'hyperband']\n",
    "    max_trials: int, maximum number of trials to run\n",
    "    overwrite: bool, whether to overwrite existing results\n",
    "    \n",
    "    Returns:\n",
    "    tuner object\n",
    "    \"\"\"\n",
    "    project_name = f\"fashion_mnist_{tuner_type}\"\n",
    "    \n",
    "    if tuner_type == 'random':\n",
    "        tuner = kt.RandomSearch(\n",
    "            build_model,\n",
    "            objective=\"val_accuracy\",\n",
    "            max_trials=max_trials,\n",
    "            directory=\"fashion_mnist_tuning\",\n",
    "            project_name=project_name,\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "    else:  # hyperband\n",
    "        tuner = kt.Hyperband(\n",
    "            build_model,\n",
    "            objective=\"val_accuracy\",\n",
    "            max_epochs=10,\n",
    "            factor=3,\n",
    "            directory=\"fashion_mnist_tuning\",\n",
    "            project_name=project_name,\n",
    "            overwrite=overwrite\n",
    "        )\n",
    "    \n",
    "    # Print search space summary\n",
    "    tuner.search_space_summary()\n",
    "    \n",
    "    # Create early stopping callback\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    # Run the search\n",
    "    tuner.search(X_train, y_train,\n",
    "                epochs=10,\n",
    "                validation_data=(X_valid, y_valid),\n",
    "                callbacks=[stop_early])\n",
    "    \n",
    "    return tuner\n",
    "\n",
    "def analyze_results(tuners):\n",
    "    \"\"\"Analyze and visualize results from different tuners.\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: Best validation accuracy progression\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for name, tuner in tuners.items():\n",
    "        trials = tuner.oracle.get_best_trials(num_trials=1)\n",
    "        trial = trials[0]\n",
    "        # Extract values from metric observations\n",
    "        val_acc = [metric.value for metric in trial.metrics.get_history('val_accuracy')]\n",
    "        plt.plot(val_acc, label=name)\n",
    "    \n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Best Model Learning Curves')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot 2: Trial results distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for name, tuner in tuners.items():\n",
    "        trials = tuner.oracle.trials\n",
    "        final_accuracies = [t.metrics.get_last_value('val_accuracy') \n",
    "                           for t in trials.values() if t.metrics.get_last_value('val_accuracy')]\n",
    "        plt.hist(final_accuracies, alpha=0.5, label=name, bins=10)\n",
    "    \n",
    "    plt.xlabel('Final Validation Accuracy')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of Trial Results')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_best_models(tuners):\n",
    "    \"\"\"Print best hyperparameters and results for each tuner.\"\"\"\n",
    "    for name, tuner in tuners.items():\n",
    "        print(f\"\\nBest hyperparameters for {name}:\")\n",
    "        best_hp = tuner.get_best_hyperparameters(1)[0]\n",
    "        print(best_hp.values)\n",
    "        \n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6598d294",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Part 4: Run the Experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run both random search and hyperband tuning\n",
    "tuners = {\n",
    "    'Random': run_tuner('random', max_trials=5),\n",
    "    'Hyperband': run_tuner('hyperband', max_trials=5)\n",
    "}\n",
    "\n",
    "# Analyze results\n",
    "analyze_results(tuners)\n",
    "print_best_models(tuners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1520b6c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Questions to Consider:\n",
    "\n",
    "1. How do Random Search and Hyperband compare in terms of:\n",
    "   - Final model performance?\n",
    "   - Search efficiency?\n",
    "   - Time to find good hyperparameters?\n",
    "\n",
    "2. Which hyperparameters seem to have the most impact on model performance?\n",
    "\n",
    "3. How might you modify the search space to improve results?\n",
    "\n",
    "4. What are the trade-offs between search time and model performance?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
